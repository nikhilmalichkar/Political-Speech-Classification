# -*- coding: utf-8 -*-
"""Political Speech Classification.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1DP6-DB_JCrDcnPD3xwF060HcUbGtZcIG
"""

# Political Speech Classification using SVM
# ---------------------------------------------

import pandas as pd
import numpy as np
import re
import string
import nltk
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
import seaborn as sns
import matplotlib.pyplot as plt

# Download NLTK stopwords
nltk.download('stopwords')
from nltk.corpus import stopwords

# -----------------------------------------------------
# 1. Load Dataset
# -----------------------------------------------------
df = pd.read_csv('/content/Dataset - EMPOLITICON NLP and ML Based Approach for Context and Emotion Classification of Political Speeches From Transcripts.csv')

print("Dataset loaded successfully âœ…")
print("Shape of dataset:", df.shape)
print("\nColumns:", df.columns.tolist())
print("\nSample Data:\n", df.head())

# -----------------------------------------------------
# 2. Basic Cleaning & Preprocessing
# -----------------------------------------------------
# Assuming 'Text' column contains speeches and 'Label' contains emotion/context labels
# (Modify if your column names differ)
text_col = 'Text_of_Speech'      # replace with actual text column name if different
label_col = 'Context'    # replace with actual label column name if different

# Clean text
def clean_text(text):
    text = str(text).lower()
    text = re.sub(r'\[.*?\]', '', text)
    text = re.sub(r'https?://\S+|www\.\S+', '', text)
    text = re.sub(r'<.*?>+', '', text)
    text = re.sub(r'[%s]' % re.escape(string.punctuation), '', text)
    text = re.sub(r'\n', '', text)
    text = re.sub(r'\w*\d\w*', '', text)
    text = re.sub(r'\s+', ' ', text).strip()
    return text

df[text_col] = df[text_col].apply(clean_text)

# Remove stopwords
stop = stopwords.words('english')
df[text_col] = df[text_col].apply(lambda x: ' '.join([word for word in x.split() if word not in stop]))

# -----------------------------------------------------
# 3. Split Data into Train/Test
# -----------------------------------------------------
X = df[text_col]
y = df[label_col]

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)

# -----------------------------------------------------
# 4. Feature Extraction (TF-IDF)
# -----------------------------------------------------
tfidf = TfidfVectorizer(max_features=5000, ngram_range=(1,2))
X_train_tfidf = tfidf.fit_transform(X_train)
X_test_tfidf = tfidf.transform(X_test)

# -----------------------------------------------------
# 5. Train SVM Classifier
# -----------------------------------------------------
svm = SVC(kernel='linear', C=1.0, random_state=42)
svm.fit(X_train_tfidf, y_train)

# -----------------------------------------------------
# 6. Model Evaluation
# -----------------------------------------------------
y_pred = svm.predict(X_test_tfidf)

print("\nModel Accuracy: {:.2f}%".format(accuracy_score(y_test, y_pred) * 100))
print("\nClassification Report:\n", classification_report(y_test, y_pred))

# Confusion Matrix
plt.figure(figsize=(8,6))
sns.heatmap(confusion_matrix(y_test, y_pred), annot=True, cmap='Blues', fmt='d')
plt.title('Confusion Matrix - Political Speech Classification')
plt.xlabel('Predicted Label')
plt.ylabel('True Label')
plt.show()